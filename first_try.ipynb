{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 天池工业AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pandas import Series, DataFrame\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import features_process\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (800, 5954)\n"
     ]
    }
   ],
   "source": [
    "#read data\n",
    "train_df = pd.read_excel('data/train_20180117.xlsx')\n",
    "test_df = pd.read_excel('data/testA_20180117.xlsx')\n",
    "print('train shape: ', train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_df: (1100, 5954)\n"
     ]
    }
   ],
   "source": [
    "frames = [train_df, test_df]\n",
    "data_df = pd.concat(frames, join='outer',ignore_index = True)\n",
    "data_df = data_df.reindex_axis(train_df.columns, axis=1)\n",
    "print('data_df:',data_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**先获取全是数值变量的特征**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Columns: 5954 entries, ID to Value\n",
      "dtypes: float64(5183), int64(759), object(12)\n",
      "memory usage: 36.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "float64_col = features_process.obtain_x(train_df,'float64')\n",
    "int64_col = features_process.obtain_x(train_df,'int64')\n",
    "object_col = features_process.obtain_x(train_df,'object')\n",
    "values_col = np.append(int64_col,float64_col)\n",
    "\n",
    "values_df = train_df[values_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**删除缺失值个数超过k=200的特征**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\setup\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 5573)\n"
     ]
    }
   ],
   "source": [
    "missing_col = features_process.col_missing(values_df, k = 100)\n",
    "values_df.drop(missing_col,axis=1,inplace=True)\n",
    "print(values_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 重复列\n",
    "**删除训练集中数据重复的列**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 2762)\n"
     ]
    }
   ],
   "source": [
    "values_df = features_process.col_deoverlapping(values_df)\n",
    "print(values_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Columns: 2762 entries, 210X17 to Value\n",
      "dtypes: float64(2434), int64(328)\n",
      "memory usage: 16.9 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(800, 2762)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_df.info()\n",
    "values_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 日期列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**获取并删除“日期”特征**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 2683)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_cols = features_process.date_cols(values_df)\n",
    "values_df.drop(date_cols,axis=1,inplace=True)\n",
    "values_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 缺失值填充"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**基于中位数填充缺失值**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values_df.to_csv('Bvalues_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#显示哪些\"列\"存在缺失值\n",
    "#values_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 2683)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_df.isnull().values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>210X17</th>\n",
       "      <th>210X19</th>\n",
       "      <th>ERROR:#N/A</th>\n",
       "      <th>210X21</th>\n",
       "      <th>210X31</th>\n",
       "      <th>210X36</th>\n",
       "      <th>210X77</th>\n",
       "      <th>210X80</th>\n",
       "      <th>210X199</th>\n",
       "      <th>210X214</th>\n",
       "      <th>...</th>\n",
       "      <th>750X1305</th>\n",
       "      <th>750X1313</th>\n",
       "      <th>750X1321</th>\n",
       "      <th>750X1329</th>\n",
       "      <th>750X1337</th>\n",
       "      <th>750X1356</th>\n",
       "      <th>750X1364</th>\n",
       "      <th>750X1383</th>\n",
       "      <th>750X1391</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>435</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.58</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.66</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.814025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>435</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.58</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.66</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.814025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>435</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.58</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.66</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.814025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>435</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.58</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.66</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.814025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>435</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.58</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.66</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.814025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>435</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.59</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.66</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.8</td>\n",
       "      <td>2.725973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>435</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.59</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.66</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.8</td>\n",
       "      <td>2.725973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>435</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.59</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.66</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.8</td>\n",
       "      <td>2.725973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>435</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.59</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.66</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.8</td>\n",
       "      <td>2.725973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>435</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.59</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.66</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.8</td>\n",
       "      <td>2.725973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>435</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.59</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.66</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.8</td>\n",
       "      <td>2.725973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>435</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.59</td>\n",
       "      <td>37.4</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.66</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.8</td>\n",
       "      <td>2.725973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>445</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.67</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.56</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.43</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.787539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>445</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.67</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.56</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.43</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.787539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>445</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.67</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.56</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.43</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.787539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>445</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.67</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.56</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.43</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.787539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>445</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.67</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.56</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.43</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.787539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>445</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.67</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.56</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.43</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.787539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>445</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.67</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.56</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.43</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.787539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>445</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.67</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.56</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.43</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.787539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>445</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.67</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.56</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.43</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.787539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>445</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.67</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.56</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.43</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.787539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>425</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.67</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.56</td>\n",
       "      <td>37.2</td>\n",
       "      <td>4.44</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.8</td>\n",
       "      <td>2.569175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>440</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.69</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.58</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.965824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>440</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.69</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.58</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.965824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>440</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.69</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.58</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.965824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>440</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.69</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.58</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.965824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>440</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.69</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.58</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.965824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>440</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.69</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.58</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.965824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>440</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.69</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.58</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>1.65</td>\n",
       "      <td>149.7</td>\n",
       "      <td>49.7</td>\n",
       "      <td>2.965824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.952017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.952017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.952017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.952017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.952017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.952017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.952017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.952017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.952017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.952017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.952017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.952017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.952017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.952017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.48</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.07</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.892322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.48</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.07</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.892322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.48</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.07</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.892322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.48</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.07</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.892322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.48</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.07</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.892322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.48</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.07</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.892322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.48</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.07</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.636885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.48</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.07</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.636885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>440</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.55</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.50</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.531850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.54</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.50</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.745536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.54</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.50</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.745536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>440</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.54</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>49.9</td>\n",
       "      <td>2.728874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>440</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.54</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>49.9</td>\n",
       "      <td>2.728874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.54</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.06</td>\n",
       "      <td>149.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.890727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>440</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.54</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.48</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.07</td>\n",
       "      <td>149.8</td>\n",
       "      <td>49.9</td>\n",
       "      <td>2.826487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>440</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>36.8</td>\n",
       "      <td>4.54</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.48</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>2.07</td>\n",
       "      <td>149.8</td>\n",
       "      <td>49.9</td>\n",
       "      <td>2.826487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11259 rows × 2683 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     210X17  210X19  ERROR:#N/A  210X21  210X31  210X36  210X77  210X80  \\\n",
       "0       750       2           0      14       1     435      96       0   \n",
       "0       750       2           0      14       1     435      96       0   \n",
       "0       750       2           0      14       1     435      96       0   \n",
       "0       750       2           0      14       1     435      96       0   \n",
       "0       750       2           0      14       1     435      96       0   \n",
       "2       750       2           0      14       1     435      96       0   \n",
       "2       750       2           0      14       1     435      96       0   \n",
       "2       750       2           0      14       1     435      96       0   \n",
       "2       750       2           0      14       1     435      96       0   \n",
       "2       750       2           0      14       1     435      96       0   \n",
       "2       750       2           0      14       1     435      96       0   \n",
       "2       750       2           0      14       1     435      96       0   \n",
       "4       750       2           0      14       1     445      96       0   \n",
       "4       750       2           0      14       1     445      96       0   \n",
       "4       750       2           0      14       1     445      96       0   \n",
       "4       750       2           0      14       1     445      96       0   \n",
       "4       750       2           0      14       1     445      96       0   \n",
       "4       750       2           0      14       1     445      96       0   \n",
       "4       750       2           0      14       1     445      96       0   \n",
       "4       750       2           0      14       1     445      96       0   \n",
       "4       750       2           0      14       1     445      96       0   \n",
       "4       750       2           0      14       1     445      96       0   \n",
       "5       750       2           0      14       1     425      96       0   \n",
       "6       750       2           0      14       1     440      96       0   \n",
       "6       750       2           0      14       1     440      96       0   \n",
       "6       750       2           0      14       1     440      96       0   \n",
       "6       750       2           0      14       1     440      96       0   \n",
       "6       750       2           0      14       1     440      96       0   \n",
       "6       750       2           0      14       1     440      96       0   \n",
       "6       750       2           0      14       1     440      96       0   \n",
       "..      ...     ...         ...     ...     ...     ...     ...     ...   \n",
       "792     750       2           0      14       1     460      96       0   \n",
       "792     750       2           0      14       1     460      96       0   \n",
       "792     750       2           0      14       1     460      96       0   \n",
       "792     750       2           0      14       1     460      96       0   \n",
       "792     750       2           0      14       1     460      96       0   \n",
       "792     750       2           0      14       1     460      96       0   \n",
       "792     750       2           0      14       1     460      96       0   \n",
       "792     750       2           0      14       1     460      96       0   \n",
       "792     750       2           0      14       1     460      96       0   \n",
       "792     750       2           0      14       1     460      96       0   \n",
       "792     750       2           0      14       1     460      96       0   \n",
       "792     750       2           0      14       1     460      96       0   \n",
       "792     750       2           0      14       1     460      96       0   \n",
       "792     750       2           0      14       1     460      96       0   \n",
       "793     750       2           0      14       1     420      96       0   \n",
       "793     750       2           0      14       1     420      96       0   \n",
       "793     750       2           0      14       1     420      96       0   \n",
       "793     750       2           0      14       1     420      96       0   \n",
       "793     750       2           0      14       1     420      96       0   \n",
       "793     750       2           0      14       1     420      96       0   \n",
       "794     750       2           0      14       1     420      96       0   \n",
       "794     750       2           0      14       1     420      96       0   \n",
       "795     750       1           0      14       1     440      96       0   \n",
       "796     750       2           0      14       1     420      96       0   \n",
       "796     750       2           0      14       1     420      96       0   \n",
       "797     750       1           0      14       1     440      96       0   \n",
       "797     750       1           0      14       1     440      96       0   \n",
       "798     750       2           0      14       1     420      96       0   \n",
       "799     750       1           0      14       1     440      96       0   \n",
       "799     750       1           0      14       1     440      96       0   \n",
       "\n",
       "     210X199  210X214    ...     750X1305  750X1313  750X1321  750X1329  \\\n",
       "0          1        2    ...         2.68      37.4      4.58      37.4   \n",
       "0          1        2    ...         2.68      37.4      4.58      37.4   \n",
       "0          1        2    ...         2.68      37.4      4.58      37.4   \n",
       "0          1        2    ...         2.68      37.4      4.58      37.4   \n",
       "0          1        2    ...         2.68      37.4      4.58      37.4   \n",
       "2          1        2    ...         2.68      37.4      4.59      37.4   \n",
       "2          1        2    ...         2.68      37.4      4.59      37.4   \n",
       "2          1        2    ...         2.68      37.4      4.59      37.4   \n",
       "2          1        2    ...         2.68      37.4      4.59      37.4   \n",
       "2          1        2    ...         2.68      37.4      4.59      37.4   \n",
       "2          1        2    ...         2.68      37.4      4.59      37.4   \n",
       "2          1        2    ...         2.68      37.4      4.59      37.4   \n",
       "4          1        2    ...         2.67      37.2      4.56      37.2   \n",
       "4          1        2    ...         2.67      37.2      4.56      37.2   \n",
       "4          1        2    ...         2.67      37.2      4.56      37.2   \n",
       "4          1        2    ...         2.67      37.2      4.56      37.2   \n",
       "4          1        2    ...         2.67      37.2      4.56      37.2   \n",
       "4          1        2    ...         2.67      37.2      4.56      37.2   \n",
       "4          1        2    ...         2.67      37.2      4.56      37.2   \n",
       "4          1        2    ...         2.67      37.2      4.56      37.2   \n",
       "4          1        2    ...         2.67      37.2      4.56      37.2   \n",
       "4          1        2    ...         2.67      37.2      4.56      37.2   \n",
       "5          1        2    ...         2.67      37.2      4.56      37.2   \n",
       "6          1        2    ...         2.69      37.3      4.58      37.3   \n",
       "6          1        2    ...         2.69      37.3      4.58      37.3   \n",
       "6          1        2    ...         2.69      37.3      4.58      37.3   \n",
       "6          1        2    ...         2.69      37.3      4.58      37.3   \n",
       "6          1        2    ...         2.69      37.3      4.58      37.3   \n",
       "6          1        2    ...         2.69      37.3      4.58      37.3   \n",
       "6          1        2    ...         2.69      37.3      4.58      37.3   \n",
       "..       ...      ...    ...          ...       ...       ...       ...   \n",
       "792        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "792        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "792        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "792        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "792        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "792        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "792        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "792        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "792        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "792        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "792        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "792        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "792        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "792        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "793        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "793        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "793        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "793        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "793        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "793        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "794        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "794        1        2    ...         2.64      36.8      4.53      37.3   \n",
       "795        1        2    ...         2.64      36.8      4.55      37.3   \n",
       "796        1        2    ...         2.65      36.8      4.54      37.3   \n",
       "796        1        2    ...         2.65      36.8      4.54      37.3   \n",
       "797        1        2    ...         2.65      36.8      4.54      37.3   \n",
       "797        1        2    ...         2.65      36.8      4.54      37.3   \n",
       "798        1        2    ...         2.65      36.8      4.54      37.3   \n",
       "799        1        2    ...         2.65      36.8      4.54      37.3   \n",
       "799        1        2    ...         2.65      36.8      4.54      37.3   \n",
       "\n",
       "     750X1337  750X1356  750X1364  750X1383  750X1391     Value  \n",
       "0        4.46     -12.7      1.66     149.7      49.7  2.814025  \n",
       "0        4.46     -12.7      1.66     149.7      49.7  2.814025  \n",
       "0        4.46     -12.7      1.66     149.7      49.7  2.814025  \n",
       "0        4.46     -12.7      1.66     149.7      49.7  2.814025  \n",
       "0        4.46     -12.7      1.66     149.7      49.7  2.814025  \n",
       "2        4.46     -12.7      1.66     149.7      49.8  2.725973  \n",
       "2        4.46     -12.7      1.66     149.7      49.8  2.725973  \n",
       "2        4.46     -12.7      1.66     149.7      49.8  2.725973  \n",
       "2        4.46     -12.7      1.66     149.7      49.8  2.725973  \n",
       "2        4.46     -12.7      1.66     149.7      49.8  2.725973  \n",
       "2        4.46     -12.7      1.66     149.7      49.8  2.725973  \n",
       "2        4.46     -12.7      1.66     149.7      49.8  2.725973  \n",
       "4        4.43     -12.7      1.65     149.7      49.7  2.787539  \n",
       "4        4.43     -12.7      1.65     149.7      49.7  2.787539  \n",
       "4        4.43     -12.7      1.65     149.7      49.7  2.787539  \n",
       "4        4.43     -12.7      1.65     149.7      49.7  2.787539  \n",
       "4        4.43     -12.7      1.65     149.7      49.7  2.787539  \n",
       "4        4.43     -12.7      1.65     149.7      49.7  2.787539  \n",
       "4        4.43     -12.7      1.65     149.7      49.7  2.787539  \n",
       "4        4.43     -12.7      1.65     149.7      49.7  2.787539  \n",
       "4        4.43     -12.7      1.65     149.7      49.7  2.787539  \n",
       "4        4.43     -12.7      1.65     149.7      49.7  2.787539  \n",
       "5        4.44     -12.7      1.65     149.7      49.8  2.569175  \n",
       "6        4.46     -12.7      1.65     149.7      49.7  2.965824  \n",
       "6        4.46     -12.7      1.65     149.7      49.7  2.965824  \n",
       "6        4.46     -12.7      1.65     149.7      49.7  2.965824  \n",
       "6        4.46     -12.7      1.65     149.7      49.7  2.965824  \n",
       "6        4.46     -12.7      1.65     149.7      49.7  2.965824  \n",
       "6        4.46     -12.7      1.65     149.7      49.7  2.965824  \n",
       "6        4.46     -12.7      1.65     149.7      49.7  2.965824  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "792      4.49     -16.8      2.06     149.8      50.0  2.952017  \n",
       "792      4.49     -16.8      2.06     149.8      50.0  2.952017  \n",
       "792      4.49     -16.8      2.06     149.8      50.0  2.952017  \n",
       "792      4.49     -16.8      2.06     149.8      50.0  2.952017  \n",
       "792      4.49     -16.8      2.06     149.8      50.0  2.952017  \n",
       "792      4.49     -16.8      2.06     149.8      50.0  2.952017  \n",
       "792      4.49     -16.8      2.06     149.8      50.0  2.952017  \n",
       "792      4.49     -16.8      2.06     149.8      50.0  2.952017  \n",
       "792      4.49     -16.8      2.06     149.8      50.0  2.952017  \n",
       "792      4.49     -16.8      2.06     149.8      50.0  2.952017  \n",
       "792      4.49     -16.8      2.06     149.8      50.0  2.952017  \n",
       "792      4.49     -16.8      2.06     149.8      50.0  2.952017  \n",
       "792      4.49     -16.8      2.06     149.8      50.0  2.952017  \n",
       "792      4.49     -16.8      2.06     149.8      50.0  2.952017  \n",
       "793      4.48     -16.8      2.07     149.8      50.0  2.892322  \n",
       "793      4.48     -16.8      2.07     149.8      50.0  2.892322  \n",
       "793      4.48     -16.8      2.07     149.8      50.0  2.892322  \n",
       "793      4.48     -16.8      2.07     149.8      50.0  2.892322  \n",
       "793      4.48     -16.8      2.07     149.8      50.0  2.892322  \n",
       "793      4.48     -16.8      2.07     149.8      50.0  2.892322  \n",
       "794      4.48     -16.8      2.07     149.8      50.0  2.636885  \n",
       "794      4.48     -16.8      2.07     149.8      50.0  2.636885  \n",
       "795      4.50     -16.8      2.06     149.8      50.0  2.531850  \n",
       "796      4.50     -16.8      2.06     149.8      50.0  2.745536  \n",
       "796      4.50     -16.8      2.06     149.8      50.0  2.745536  \n",
       "797      4.49     -16.8      2.06     149.8      49.9  2.728874  \n",
       "797      4.49     -16.8      2.06     149.8      49.9  2.728874  \n",
       "798      4.49     -16.8      2.06     149.8      50.0  2.890727  \n",
       "799      4.48     -16.8      2.07     149.8      49.9  2.826487  \n",
       "799      4.48     -16.8      2.07     149.8      49.9  2.826487  \n",
       "\n",
       "[11259 rows x 2683 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#只显示存在缺失值行的数据\n",
    "values_df[values_df.isnull().values==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-7a515cf64062>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvalues_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_nan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "values_df = features.fill_nan(values_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 相同值列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**获取相同值的列名，并且删除该列**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 2683/2683 [00:00<00:00, 11011.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 2644)\n"
     ]
    }
   ],
   "source": [
    "uniq_col = features_process.values_uniq(values_df)\n",
    "values_df.drop(uniq_col,axis=1,inplace=True)\n",
    "print(values_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5095889116158334"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_df[col].mode().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561\n",
      "(800, 2083)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for col in values_df.columns:\n",
    "    mode = values_df[col].mode().iloc[0]\n",
    "    flag = (values_df[col] == int(mode))\n",
    "    if sum(flag) > 300:\n",
    "        count += 1\n",
    "        values_df.drop(col, axis=1, inplace=True)\n",
    "print(count)\n",
    "print(values_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values_df.to_csv('train_2083.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 特征相关性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对所有特征计算皮尔逊系数，并且剔除相关系数大于0.95的特征**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#corr 为所有特征的相关系数矩阵\n",
    "corr = values_df.corr(method='pearson',min_periods=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "剔除相关性系数大于0.970000的特征个数：1015  \n"
     ]
    }
   ],
   "source": [
    "corr_columns = corr.columns\n",
    "num = corr.shape[0]\n",
    "\n",
    "for i in range(num):\n",
    "    for j in range(i, num):\n",
    "        corr.iloc[i,j:] = 0\n",
    "        break\n",
    "corr.to_csv('corr_0.csv')\n",
    "corr_coef = 0.97\n",
    "count=0\n",
    "for i in range(num):\n",
    "    if abs(corr.iloc[::,i].max())>corr_coef:\n",
    "        count += 1\n",
    "        values_df.drop(corr_columns[i], axis=1, inplace=True)\n",
    "print('剔除相关性系数大于%f的特征个数：%d  '%(corr_coef, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1068)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values_df.to_csv('train_1068.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 特征-目标值相关性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对特征和目标值做相关性分析，删除相关性低的特征**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cmh\\Desktop\\tianchi1.9\\features_process.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  decorr_train['Value'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 186)\n"
     ]
    }
   ],
   "source": [
    "values_decorr = features_process.cal_corrcoef(values_df, corr=0.1)\n",
    "print(values_decorr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 186)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_df = values_decorr\n",
    "values_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values_df.to_csv('train_186.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 模型 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1训练、测试数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**获得训练数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 286)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_df = pd.read_csv('Blast_value_df.csv',index_col=0)\n",
    "values_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = values_df['Value'].values\n",
    "#label = values_df['label'].values\n",
    "train_col = values_df.columns.tolist()\n",
    "train_col.remove('Value')\n",
    "#train_col.remove('label')\n",
    "x_train = values_df[train_col].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**获得测试数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\setup\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:3549: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_excel('data/testA_20180117.xlsx')\n",
    "sub_test = test_df[train_col]\n",
    "sub_test.fillna(sub_test.median(),inplace=True)\n",
    "x_test = sub_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据归一化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\setup\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:160: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X = np.vstack((x_train,x_test))\n",
    "X = preprocessing.scale(X)\n",
    "x_train = X[0:len(x_train)]\n",
    "x_test = X[len(x_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=DataFrame(x_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn import preprocessing \\nX = np.vstack((x_train,x_test))\\nmin_max_scaler = preprocessing.MinMaxScaler()\\nX = min_max_scaler.fit_transform(X)\\nx_train = X[0:len(x_train)]\\nx_test = X[len(x_train):]\\n'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn import preprocessing \n",
    "X = np.vstack((x_train,x_test))\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "x_train = X[0:len(x_train)]\n",
    "x_test = X[len(x_train):]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn import preprocessing\\n# normalize the data attributes\\nnormalized_X = preprocessing.normalize(X)\\n# standardize the data attributes\\nstandardized_X = preprocessing.scale(X)\\nx_train = X[0:len(x_train)]\\nx_test = X[len(x_train):]\\n'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn import preprocessing\n",
    "# normalize the data attributes\n",
    "normalized_X = preprocessing.normalize(X)\n",
    "# standardize the data attributes\n",
    "standardized_X = preprocessing.scale(X)\n",
    "x_train = X[0:len(x_train)]\n",
    "x_test = X[len(x_train):]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1529887c0b8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6MAAAKqCAYAAADPHohgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15298891dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values_df.iloc[::,5].hist(bins=50, figsize=(16,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.subplots(figsize=(16,9))\n",
    "correlation_mat = values_df.corr()\n",
    "sns.heatmap(correlation_mat, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN回归**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.036306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import neighbors  \n",
    "\n",
    "reg = neighbors.KNeighborsRegressor(n_neighbors=5)\n",
    "num = list(range(y_train.shape[0]))\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "mse = []\n",
    "for tr, val in loo.split(num):\n",
    "    reg.fit(x_train[tr], y_train[tr])  \n",
    "    y_pred = reg.predict(x_train[val])\n",
    "    mse.append(mean_squared_error(y_pred, y_train[val]))\n",
    "\n",
    "print(\"MSE = %f\"%(sum(mse)/len(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.78416721]), array([ 2.9260329]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, y_train[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg.fit(x_train,y_train)\n",
    "y_pred = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.61057637,  2.61057637,  2.78894771,  2.94075098,  2.78052814,\n",
       "        2.88786448,  2.81552779,  2.8412337 ,  2.81750404,  2.80406221,\n",
       "        2.66015124,  3.07038591,  2.75839412,  2.83517488,  2.975137  ,\n",
       "        2.84482137,  2.8802378 ,  2.86344715,  2.75681498,  2.68580636,\n",
       "        2.94457644,  2.70945217,  2.79963005,  2.69560688,  2.70945217,\n",
       "        2.81483191,  2.74195161,  2.7749339 ,  2.82388249,  2.82272918,\n",
       "        2.74399672,  2.88253139,  2.68598118,  2.79311981,  2.83738511,\n",
       "        2.88115034,  2.79471776,  2.79430456,  2.75015952,  2.88426369,\n",
       "        2.72698779,  2.85541871,  2.76417634,  2.85002832,  2.77368665,\n",
       "        2.81155259,  2.76748024,  2.74417818,  2.72229157,  2.75601581,\n",
       "        2.70749017,  2.97467853,  3.00205891,  2.71218007,  2.71473187,\n",
       "        2.67853694,  2.84399013,  2.8395072 ,  2.81496058,  2.93238491,\n",
       "        2.93744879,  2.79481604,  2.6638877 ,  2.89430919,  2.64271747,\n",
       "        2.80119287,  2.87898276,  2.78979973,  2.96594469,  2.71088433,\n",
       "        2.78979973,  2.65364635,  2.5983711 ,  2.71042818,  2.66015124,\n",
       "        2.88366977,  2.71850857,  2.59502752,  2.69735544,  2.99928773,\n",
       "        2.78489539,  2.79780148,  2.89087887,  2.81435487,  2.87777473,\n",
       "        2.78894771,  2.87292012,  2.94486561,  2.96082731,  2.85606567,\n",
       "        2.78715392,  2.78894771,  2.64245505,  2.84428264,  2.80307505,\n",
       "        2.68673784,  2.62441491,  2.71989528,  3.0913962 ,  2.71420148])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('subA.csv',header=None)\n",
    "sub_df['Y'] = y_pred\n",
    "sub_df.to_csv('test_A4.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "#dtrain = xgb.DMatrix(x_train[0:460,:],label = y_train[:460])\n",
    "#dtest = xgb.DMatrix(x_test,label = y_test)\n",
    "#dtest = xgb.DMatrix(x_train[460:,:],label = y_train[460:])\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [800, 680]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-ff7d92395f8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files\\setup\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2037\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2038\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2039\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2040\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2041\u001b[0m         cv = StratifiedShuffleSplit(stratify, test_size=test_size,\n",
      "\u001b[1;32mC:\\Program Files\\setup\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\setup\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 181\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [800, 680]"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = cross_validation.train_test_split(x_train, y_train, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(x_train,label = y_train)\n",
    "#dtest = xgb.DMatrix(x_test,label = y_test)\n",
    "#dval = xgb.DMatrix(X_val,label = y_val)\n",
    "dtest = xgb.DMatrix(x_test,label = y_train[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify parameters via map\n",
    "param = {'max_depth':2, 'eta':0.1,'learning_rate':0.05, 'silent':1, 'objective':'reg:linear','eval_metric':'rmse' ,'lambda':200,'alpha':2}\n",
    "#param = {'eta':0.1,'learning_rate':0.05, 'silent':1,'booster':'gbliner', 'objective':'reg:linear','eval_metric':'rmse' ,'lambda':2,'alpha':2}\n",
    "\n",
    "# 设置boosting迭代计算次数\n",
    "num_round = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "bst = xgb.train(param, dtrain, num_round) \n",
    "val_pred = bst.predict(dtest)\n",
    "train_pred = bst.predict(dtrain)\n",
    "train_mse=(mean_squared_error(train_pred, y_train))\n",
    "validation_mse=(mean_squared_error(val_pred, y_train[0:100]))\n",
    "print(\"train_MSE = %f\"%train_mse)\n",
    "print(\"validation_MSE = %f\"%validation_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('subA.csv',header=None)\n",
    "sub_df['Y'] = val_pred\n",
    "sub_df.to_csv('test_A5.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "parameters = {'objective':['reg:linear'],\n",
    "              'learning_rate': [0.05],\n",
    "              'max_depth': [5,6],\n",
    "              'min_child_weight':[11],\n",
    "             'silent':[1],\n",
    "             'n_estimators':[5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'ShuffleSplit' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-dc495083210f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m                   \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                   verbose=2, refit=True)\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\setup\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m         \"\"\"\n\u001b[1;32m--> 829\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\setup\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    556\u001b[0m                 \u001b[0mn_candidates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameter_iterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m                 print(\"Fitting {0} folds for each of {1} candidates, totalling\"\n\u001b[1;32m--> 558\u001b[1;33m                       \" {2} fits\".format(len(cv), n_candidates,\n\u001b[0m\u001b[0;32m    559\u001b[0m                                          n_candidates * len(cv)))\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'ShuffleSplit' has no len()"
     ]
    }
   ],
   "source": [
    "cv_sets = ShuffleSplit(n_splits = 10, test_size = 0.20, random_state = 0)\n",
    "clf = GridSearchCV(xgb_model, param_grid=parameters,\n",
    "                  cv=cv_sets,\n",
    "                  scoring='neg_mean_squared_error',\n",
    "                  verbose=2, refit=True)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b8e2a279a9bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mskf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mskf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "num = list(range(y_train.shape[0]))\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(x_train, y_train)\n",
    "loo = LeaveOneOut()\n",
    "mse = []\n",
    "for tr, val in loo.split(num):\n",
    "    dtrain = xgb.DMatrix(x_train[tr],label = y_train[tr])\n",
    "    #dtest = xgb.DMatrix(x_test,label = y_test)\n",
    "    dval = xgb.DMatrix(x_train[val],label = y_train[val])\n",
    "    bst = xgb.train(param, dtrain, num_round) \n",
    "    val_pred = bst.predict(dval)\n",
    "    mse.append(mean_squared_error(val_pred, y_train[val]))\n",
    "    print(val)\n",
    "print(\"MSE = %f\"%(sum(mse)/len(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.61057637,  2.61057637,  2.78894771,  2.94075098,  2.78052814,\n",
       "         2.88786448,  2.81552779,  2.8412337 ,  2.81750404,  2.80406221,\n",
       "         2.66015124,  3.07038591,  2.75839412,  2.83517488,  2.975137  ,\n",
       "         2.84482137,  2.8802378 ,  2.86344715,  2.75681498,  2.68580636,\n",
       "         2.94457644,  2.70945217,  2.79963005,  2.69560688,  2.70945217,\n",
       "         2.81483191,  2.74195161,  2.7749339 ,  2.82388249,  2.82272918,\n",
       "         2.74399672,  2.88253139,  2.68598118,  2.79311981,  2.83738511,\n",
       "         2.88115034,  2.79471776,  2.79430456,  2.75015952,  2.88426369,\n",
       "         2.72698779,  2.85541871,  2.76417634,  2.85002832,  2.77368665,\n",
       "         2.81155259,  2.76748024,  2.74417818,  2.72229157,  2.75601581,\n",
       "         2.70749017,  2.97467853,  3.00205891,  2.71218007,  2.71473187,\n",
       "         2.67853694,  2.84399013,  2.8395072 ,  2.81496058,  2.93238491,\n",
       "         2.93744879,  2.79481604,  2.6638877 ,  2.89430919,  2.64271747,\n",
       "         2.80119287,  2.87898276,  2.78979973,  2.96594469,  2.71088433,\n",
       "         2.78979973,  2.65364635,  2.5983711 ,  2.71042818,  2.66015124,\n",
       "         2.88366977,  2.71850857,  2.59502752,  2.69735544,  2.99928773,\n",
       "         2.78489539,  2.79780148,  2.89087887,  2.81435487,  2.87777473,\n",
       "         2.78894771,  2.87292012,  2.94486561,  2.96082731,  2.85606567,\n",
       "         2.78715392,  2.78894771,  2.64245505,  2.84428264,  2.80307505,\n",
       "         2.68673784,  2.62441491,  2.71989528,  3.0913962 ,  2.71420148]),\n",
       " array([ 2.94507888]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, y_train[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0133584718704\n"
     ]
    }
   ],
   "source": [
    "train_pred = bst.predict(dtrain)\n",
    "#train_predictions = [round(value) for value in train_preds]\n",
    "y_train1 = dtrain.get_label()\n",
    "#train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "#print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "mse = 1/500 * np.sum(np.square(y_train1-train_pred))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.77278913,  2.782469  ,  3.31040605,  2.84601751,  2.95788437,\n",
       "        3.22707774,  2.65260576,  2.93532712,  2.88298069,  2.74874291,\n",
       "        2.87732058,  2.78536975,  2.64594474,  2.80316417,  2.56330528,\n",
       "        3.12929649,  2.75976702,  3.06259109,  2.83297147,  2.93598543,\n",
       "        2.89830038,  3.02749429,  2.91570109,  3.11237871,  2.64958246,\n",
       "        2.60694199,  2.85853727,  2.6319409 ,  3.02939638,  2.84612516,\n",
       "        3.02446789,  3.05155672,  3.05495253,  2.93741112,  2.88116379,\n",
       "        2.88574334,  2.62334152,  3.0151373 ,  2.75328635,  2.9260329 ])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0382936394885\n"
     ]
    }
   ],
   "source": [
    "# make prediction\n",
    "y_test = y_train[460:]\n",
    "test_preds = bst.predict(dtest)\n",
    "mse_test = 1/(y_test.shape[0]) * np.sum(np.square(y_test-test_preds))\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.77278913,  2.782469  ,  3.31040605,  2.84601751,  2.95788437,\n",
       "        3.22707774,  2.65260576,  2.93532712,  2.88298069,  2.74874291,\n",
       "        2.87732058,  2.78536975,  2.64594474,  2.80316417,  2.56330528,\n",
       "        3.12929649,  2.75976702,  3.06259109,  2.83297147,  2.93598543,\n",
       "        2.89830038,  3.02749429,  2.91570109,  3.11237871,  2.64958246,\n",
       "        2.60694199,  2.85853727,  2.6319409 ,  3.02939638,  2.84612516,\n",
       "        3.02446789,  3.05155672,  3.05495253,  2.93741112,  2.88116379,\n",
       "        2.88574334,  2.62334152,  3.0151373 ,  2.75328635,  2.9260329 ])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-03079a58a099>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_preds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_preds' is not defined"
     ]
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-edd3bdd168cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msub_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'subA.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msub_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Y'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msub_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_A3.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_preds' is not defined"
     ]
    }
   ],
   "source": [
    "sub_df = pd.read_csv('subA.csv',header=None)\n",
    "sub_df['Y'] = test_preds\n",
    "sub_df.to_csv('test_A3.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特征重要度排序**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA7lRWWLFxylOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x218ed654da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04066543  0.00184843  0.02033272  0.          0.          0.012939\n",
      "  0.00369686  0.012939    0.00184843  0.04621072  0.03142329  0.00739372\n",
      "  0.00924214  0.02033272  0.01109057  0.02772643  0.02957486  0.00369686\n",
      "  0.00739372  0.00554529  0.00554529  0.00554529  0.00554529  0.02957486\n",
      "  0.012939    0.          0.00184843  0.01478743  0.00369686  0.00739372\n",
      "  0.03512015  0.          0.00739372  0.01848429  0.00369686  0.00739372\n",
      "  0.          0.00554529  0.00184843  0.          0.          0.\n",
      "  0.00369686  0.00369686  0.          0.01109057  0.00369686  0.00369686\n",
      "  0.00184843  0.          0.          0.          0.00554529  0.          0.\n",
      "  0.00369686  0.          0.00369686  0.          0.025878    0.05545286\n",
      "  0.00184843  0.00554529  0.00369686  0.00739372  0.00369686  0.\n",
      "  0.00369686  0.00369686  0.00739372  0.01663586  0.00739372  0.01478743\n",
      "  0.00739372  0.          0.00554529  0.00184843  0.          0.          0.\n",
      "  0.          0.          0.          0.03327172  0.01109057  0.00739372\n",
      "  0.00184843  0.          0.00184843  0.00369686  0.          0.012939\n",
      "  0.01109057  0.00184843  0.00184843  0.00739372  0.02957486  0.00369686\n",
      "  0.00924214  0.          0.          0.00924214  0.01109057  0.00369686\n",
      "  0.00554529  0.01848429  0.00739372  0.00924214  0.00369686  0.\n",
      "  0.00924214  0.          0.          0.          0.          0.00369686\n",
      "  0.00184843  0.          0.          0.02957486  0.02033272  0.00739372\n",
      "  0.          0.00739372  0.          0.00739372  0.02772643  0.00369686\n",
      "  0.          0.00369686]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x218ed6433c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as pyplot\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import metrics\n",
    "model_XGB=XGBRegressor()\n",
    "model_XGB.fit(x_train,y_train)\n",
    "plot_importance(model_XGB)\n",
    "pyplot.show()\n",
    "pyplot.savefig('D:\\\\feture_importance.svg',format='svg')\n",
    "print(model_XGB.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 结果导出到文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('subA.csv',header=None)\n",
    "sub_df['Y3'] = y_pred\n",
    "sub_df.to_csv('github1.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = []\n",
    "for i in range(100):\n",
    "    if answer[i] == 1:\n",
    "        sub.append (2.50)\n",
    "    elif answer[i] == 2:\n",
    "        sub.append(2.62)\n",
    "    elif answer[i] == 3:\n",
    "        sub.append(2.7)\n",
    "    elif answer[i] == 4:\n",
    "        sub.append(2.75)\n",
    "    elif answer[i] == 5:\n",
    "        sub.append(2.80)\n",
    "    elif answer[i] == 6:\n",
    "        sub.append(2.85)\n",
    "    elif answer[i] == 7:\n",
    "        sub.append(2.90)\n",
    "    elif answer[i] == 8:\n",
    "        sub.append(2.96)\n",
    "    elif answer[i] == 9:\n",
    "        sub.append(3.06)\n",
    "    elif answer[i] == 10:\n",
    "        sub.append(3.16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
